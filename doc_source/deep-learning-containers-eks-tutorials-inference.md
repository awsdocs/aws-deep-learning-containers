# Inference<a name="deep-learning-containers-eks-tutorials-inference"></a>

Once you've created a cluster using the steps in [Amazon EKS Setup](deep-learning-containers-eks-setup.md), you can use it to run inference jobs\. For inference, you can use either a CPU or GPU example depending on the nodes in your cluster\. Inference supports only single node configurations\. The following topics show how to run inference with AWS Deep Learning Containers on EKS using Apache MXNet \(Incubating\), PyTorch, TensorFlow, and TensorFlow 2\.

**Topics**
+ [CPU Inference](deep-learning-containers-eks-tutorials-cpu-inference.md)
+ [GPU Inference](deep-learning-containers-eks-tutorials-gpu-inference.md)